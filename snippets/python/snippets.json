{
  "print": {
    "prefix": "prt",
    "body": [
      "print(${1:message})"
    ],
    "description": "Print statement"
  },
  "with open read": {
    "prefix": "wor",
    "body": [
      "with open(${1:file_path}, 'r') as ${2:f}:",
      "\t${3:# file operations}"
    ],
    "description": "With statement for reading files"
  },
  "with open write": {
    "prefix": "wow",
    "body": [
      "with open(${1:file_path}, 'w') as ${2:f}:",
      "\t${3:# file operations}"
    ],
    "description": "With statement for writing files"
  },
  "counter": {
    "prefix": "cnt",
    "body": [
      "from collections import Counter",
      "",
      "c = Counter(${1:iterable})"
    ],
    "description": "Counter from collections"
  },
  "patate debug": {
    "prefix": "ptt",
    "body": [
      "print(\"ü•îü•îü•î\", ${1:var})"
    ],
    "description": "patate debug"
  },
  "Import common data libraries": {
    "prefix": "impdata",
    "body": [
      "import numpy as np",
      "import pandas as pd",
      "import matplotlib.pyplot as plt",
      "import seaborn as sns"
    ],
    "description": "Import common data science libraries"
  },
  "List comprehension": {
    "prefix": "cl",
    "body": [
      "${1:result} = [${2:expression} for ${3:item} in ${4:iterable}]"
    ],
    "description": "List comprehension"
  },
  "List comprehension with condition": {
    "prefix": "clc",
    "body": [
      "${1:result} = [${2:expression} for ${3:item} in ${4:iterable} if ${5:condition}]"
    ],
    "description": "List comprehension with condition"
  },
  "Dictionary comprehension": {
    "prefix": "cd",
    "body": [
      "${1:result} = {${2:key}: ${3:value} for ${4:item} in ${5:iterable}}"
    ],
    "description": "Dictionary comprehension"
  },
  "Function definition": {
    "prefix": "fndef",
    "body": [
      "def ${1:function_name}(${2:parameters}):",
      "\t\"\"\"${3:Docstring describing the function}",
      "\t",
      "\tArgs:",
      "\t\t${4:param_name}: ${5:param_description}",
      "\t",
      "\tReturns:",
      "\t\t${6:return_description}",
      "\t\"\"\"",
      "\t${7:pass}"
    ],
    "description": "Function definition with docstring"
  },
  "Class definition": {
    "prefix": "cldef",
    "body": [
      "class ${1:ClassName}:",
      "\t\"\"\"${2:Class docstring}\"\"\"",
      "\t",
      "\tdef __init__(self, ${3:parameters}):",
      "\t\t\"\"\"Initialize the ${1:ClassName} instance.",
      "\t\t",
      "\t\tArgs:",
      "\t\t\t${4:param_name}: ${5:param_description}",
      "\t\t\"\"\"",
      "\t\t${6:pass}",
      "\t",
      "\tdef ${7:method_name}(self, ${8:parameters}):",
      "\t\t\"\"\"${9:Method docstring}",
      "\t\t",
      "\t\tArgs:",
      "\t\t\t${10:param_name}: ${11:param_description}",
      "\t\t",
      "\t\tReturns:",
      "\t\t\t${12:return_description}",
      "\t\t\"\"\"",
      "\t\t${13:pass}"
    ],
    "description": "Class definition with methods and docstrings"
  },
  "Try except": {
    "prefix": "tryex",
    "body": [
      "try:",
      "\t${1:# code that might raise an exception}",
      "except ${2:Exception} as ${3:e}:",
      "\t${4:# handle the exception}",
      "\tprint(f\"Error: {${3:e}}\")"
    ],
    "description": "Try-except block"
  },
  "Try except else finally": {
    "prefix": "tryexef",
    "body": [
      "try:",
      "\t${1:# code that might raise an exception}",
      "except ${2:Exception} as ${3:e}:",
      "\t${4:# handle the exception}",
      "\tprint(f\"Error: {${3:e}}\")",
      "else:",
      "\t${5:# code to run if no exception}",
      "finally:",
      "\t${6:# code to run always}"
    ],
    "description": "Try-except-else-finally block"
  },
  "With open file": {
    "prefix": "with",
    "body": [
      "with open(${1:file_path}, '${2:r}') as ${3:f}:",
      "\t${4:# file operations}"
    ],
    "description": "With statement for file operations"
  },
  "LangChain prompt template": {
    "prefix": "lcpt",
    "body": [
      "from langchain.prompts import PromptTemplate",
      "",
      "# Define a prompt template",
      "prompt_template = PromptTemplate.from_template(",
      "\"\"\"",
      "${1:prompt_text}",
      "Formato richiesto: {${2:format_instructions}}",
      "Input JSON: {${3:input_json}}",
      "\"\"\"",
      ")"
    ],
    "description": "Create a LangChain prompt template"
  },
  "LangChain model": {
    "prefix": "lcm",
    "body": [
      "from langchain.chat_models import init_chat_model",
      "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0.0)",
      ")"
    ],
    "description": "Initialize a LangChain model"
  },
  "Pydantic model": {
    "prefix": "pyd",
    "body": [
      "from pydantic import BaseModel, Field",
      "from typing import Optional",
      "class ${1:Model}(BaseModel):",
      "\t${2:field_name}: ${3:field_type} = Field(..., description=\"${4:Field description}\")"
    ],
    "description": "Create a Pydantic model"
  },
  "LangChain pydantic parser": {
    "prefix": "lcpp",
    "body": [
      "from langchain.output_parsers import PydanticOutputParser",
      "",
      "${parser} = PydanticOutputParser(pydantic_object=${1:model_name})"
    ],
    "description": "Create a Pydantic output parser for LangChain"
  },
  "LangChain  basic chain": {
    "prefix": "lcc",
    "body": [
      "from langchain.output_parsers import PydanticOutputParser",
      "from langchain.chat_models import init_chat_model",
      "from langchain.prompts import PromptTemplate",
      "",
      "prompt = PromptTemplate.from_template(",
      "\"\"\"",
      "prompt_text",
      "Formato richiesto: {format_instructions}",
      "Input JSON: {input_json}",
      "\"\"\"",
      ")",
      "llm = init_chat_model(\"gpt-4o-mini\", model_provider=\"openai\", temperature=0.0)",
      "${parser} = PydanticOutputParser(pydantic_object=model)",
      "similarity_llm = prompt | llm | parser"
    ],
    "description": "Create a Pydantic output parser for LangChain"
  },
  "LangChain RAG setup": {
    "prefix": "lcrag",
    "body": [
      "from langchain.document_loaders import ${1:TextLoader}",
      "from langchain.text_splitter import RecursiveCharacterTextSplitter",
      "from langchain.embeddings import OpenAIEmbeddings",
      "from langchain.vectorstores import Chroma",
      "from langchain.chains import RetrievalQA",
      "from langchain.llms import OpenAI",
      "",
      "# 1. Load documents",
      "loader = ${1:TextLoader}(\"${2:path/to/document}\")",
      "documents = loader.load()",
      "",
      "# 2. Split documents into chunks",
      "text_splitter = RecursiveCharacterTextSplitter(",
      "\tchunk_size=${3:1000},",
      "\tchunk_overlap=${4:100}",
      ")",
      "chunks = text_splitter.split_documents(documents)",
      "",
      "# 3. Create embeddings and vectorstore",
      "embeddings = OpenAIEmbeddings()",
      "vectorstore = Chroma.from_documents(chunks, embeddings)",
      "",
      "# 4. Create a retrieval chain",
      "qa_chain = RetrievalQA.from_chain_type(",
      "\tllm=OpenAI(),",
      "\tchain_type=\"stuff\",",
      "\tretriever=vectorstore.as_retriever()",
      ")",
      "",
      "# 5. Ask a question",
      "result = qa_chain({\"query\": \"${5:Your question about the documents?}\"})"
    ],
    "description": "Set up a Retrieval Augmented Generation (RAG) system with LangChain"
  },
  "Import pathlib": {
    "prefix": "pathlibi",
    "body": [
      "from pathlib import Path"
    ],
    "description": "Import Path from pathlib"
  },
  "argparser": {
    "prefix": "argp",
    "body": [
      "import argparse",
      "",
      "parser = argparse.ArgumentParser(description=\"${1:Description of your script}\")",
      "",
      "parser.add_argument('--${2:arg_name}', type=${3:str}, help='${4:Description of the argument}')",
      "",
      "args = parser.parse_args()",
      "",
      "print(args.${2:arg_name})",
      "",
      "if args.${2:arg_name} is None:",
      "\ttry:",
      "\t\tfilepath = input('Inserisci il dato').strip()",
      "\texcept EOFError:",
      "\t\tprint(\"EOFError: No input received\")",
      "\t\treturn"
    ],
    "description": "Set up an argument parser"
  },
  "with open": {
    "prefix": "opn",
    "body": [
      "with open(${1:file_path}, '${2:r}', encoding='utf-8') as ${3:f}:",
      "\t${4:# file operations}"
    ],
    "description": "With statement for file operations"
  },
  "cli multimode": {
    "prefix": "clit",
    "body": [
      "import argparse",
      "",
      "def cli():",
      "\tparser = argparse.ArgumentParser(description=\"${1:CLI con pi√π modalit√†}\")",
      "\tparser.add_argument('--parse', type=str, help='Modalit√† parse, nome file da analizzare')",
      "\tparser.add_argument('-a', type=str, help='Modalit√† analisi, nome file da analizzare')",
      "\tparser.add_argument('-b', nargs=2, help='Modalit√† confronto, due nomi di file')",
      "\targs = parser.parse_args()",
      "",
      "\tmodes = {",
      "\t\t\"parse\": args.parse,",
      "\t\t\"a\": args.a,",
      "\t\t\"b\": args.b",
      "\t}",
      "",
      "\tselected_mode_key = [k for k, v in modes.items() if v is not None]",
      "",
      "\tif not selected_mode_key:",
      "\t\tparser.print_help()",
      "\t\treturn",
      "",
      "\tmatch selected_mode_key[0]:",
      "\t\tcase \"parse\":",
      "\t\t\tpdf_name = modes[\"parse\"]",
      "\t\t\tprint(f\"Parse mode selected for {pdf_name}\")",
      "",
      "\t\tcase \"a\":",
      "\t\t\tpdf_name = modes[\"a\"]",
      "\t\t\tprint(f\"Analisi mode selected for {pdf_name}\")",
      "",
      "\t\tcase \"b\":",
      "\t\t\tpdf_paths = [f\"./out_analisi/{x}\" for x in modes[\"b\"]]",
      "\t\t\tprint(f\"Confronto emendativo tra {pdf_paths[0]} e {pdf_paths[1]}\")",
      "",
      "\t\tcase _:",
      "\t\t\tprint(\"Modalit√† non riconosciuta.\")",
      "",
      "if __name__ == '__main__':",
      "\tcli()"
    ],
    "description": "CLI multimodale con argparse e match-case"
  }
}
